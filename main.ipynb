{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case Mr.Health - Cientista de Dados - DataLakers\n",
    "\n",
    "Israel Segalin, 04/05/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando as bibliotecas necessárias\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lendo as planilhas de dados para Análise Exploratória\n",
    "pedidos = pd.read_excel('datasets/pedidos.xlsx')\n",
    "detalhesPedidos = pd.read_excel('datasets/detalhespedido.xlsx')\n",
    "itens = pd.read_excel('itens.xlsx')\n",
    "\n",
    "#Exibe as informações de cada dataset para análise\n",
    "itens.info()\n",
    "print('\\n')\n",
    "pedidos.info()\n",
    "print('\\n')\n",
    "detalhesPedidos.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fazendo uma análise breve nas infos de cada planilha, percebemos que a \"itens\" cataloga os produtos oferecidos pelo estabelecimento e em seguida seu valor p/unidade (embora esteja incompleto e precisemos nomear as colunas).\n",
    "\n",
    "Também percebemos que a \"detalhespedido\" cita os detalhes dos pedidos listados justamente na planilha \"pedidos\", podendo ser associados pela ID do pedido.\n",
    "\n",
    "Porém, percebemos que a \"detalhespedido\" separa o pedido por tipos de produto, mantendo a id, mas em linhas diferentes, causando uma discrepância na quantidade final de linhas em cada tabela, já que a \"pedidos\", considera apenas o pedido como um todo (considerando todos diferentes produtos).\n",
    "\n",
    "Para análise posterior, precisaremos preencher a coluna VALOR_TOTAL, que está vazia (NaN), então recriaremos uma única tabela contendo as informações juntas de todas as outras tabelas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itens = itens.rename(columns={\"Unnamed: 0\": \"ID_ITEM\", 0:\"PREÇO_UNIDADE\"}) #Corrigindo colunas dos itens\n",
    "itens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenando os datasets de pedidos e detalhes dos pedidos\n",
    "df = pedidos.merge(detalhesPedidos, on='ID_PEDIDO', how='left')\n",
    "df = df[['ID_PEDIDO', 'DATA', 'VALOR_TOTAL', 'ID_ITEM', 'QUANTIDADE']] #Deixando apenas as colunas necessárias\n",
    "df.info()\n",
    "#Aqui juntamos todos os pedidos com os detalhes, tendo toda divisão de itens mas com as datas da tabela \"pedidos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acima percebemos que a DATA está no tipo OBJECT (String), então irei converte-la para o datetime\n",
    "df['DATA'] = pd.to_datetime(df['DATA'])\n",
    "\n",
    "df = pd.merge(df, itens, on=\"ID_ITEM\") #Concatenando os pedidos com os preços_unidade, baseado na ID do item\n",
    "\n",
    "#Calculando o VALOR_TOTAL para cada linha, multiplicando a quantidade pelo preço_unidade\n",
    "for index, row in df.iterrows():\n",
    "    df.at[index, \"VALOR_TOTAL\"] = (df.at[index, \"QUANTIDADE\"]) * df.at[index, \"PREÇO_UNIDADE\"]\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iniciando a análise exploratória em busca de problemas nos dados.\n",
    "\n",
    "#Verificando se existem valores duplicados\n",
    "#Aqui abro ponto de dúvida. Neste caso, precisariam ser discutidas as regras de negócio, pois em alguns pedidos, a linha se repete pois se trata do mesmo\n",
    "#item e mesma quantidade, porém, nada impediria o usuário/cliente de adicionar o mesmo produto no mesmo pedido em duas vezes distintas (começo e fim)\n",
    "#Mas por consideração ética de que quando o mesmo produto é adicionado no pedido, apenas aumenta a quantidade, removerei os duplicados.\n",
    "linhas_duplicadas = df[df.duplicated(keep=False)] #Variável para visualizar os valores duplicados\n",
    "\n",
    "if df.duplicated().any():\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "#Conhecendo os dados\n",
    "print(df.shape,\"\\n\")\n",
    "print(df.head(),\"\\n\")\n",
    "print(df.info(),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A visualização acima já é mais do que suficiente para sabermos que não existem valores nulos, mas executaremos outra análise por segurança.\n",
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descrição dos valores das colunas para procurar possíveis inconsistências\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que garanti a qualidade dos dados e o dataset está pronto, posso começar a realizar uma análise descritiva para buscar entender padrões, correlações, comportamentos, e outras características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observando qual foi o item mais pedido no intervalo de tempo\n",
    "item_mais_vendido = df.groupby(df['ID_ITEM']).agg({'QUANTIDADE': 'sum'}).reset_index()\n",
    "plt.bar(item_mais_vendido['ID_ITEM'], item_mais_vendido['QUANTIDADE'], color='skyblue')\n",
    "item_mais_vendido.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observando o mês com mais vendas\n",
    "vendas_mensais = df.set_index('DATA', inplace=False).resample('ME').sum()\n",
    "vendas_mensais.reset_index(inplace=True)\n",
    "vendas_mensais['DATA'] = vendas_mensais['DATA'].dt.strftime('%m/%Y')\n",
    "plt.plot(vendas_mensais['DATA'], vendas_mensais['VALOR_TOTAL'])\n",
    "vendas_mensais[['DATA', 'VALOR_TOTAL']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observando vendas diárias\n",
    "vendas_diarias = df.set_index('DATA', inplace=False).resample('D').sum()\n",
    "vendas_diarias.reset_index(inplace=True)\n",
    "vendas_diarias['DATA'] = vendas_diarias['DATA'].dt.strftime('%d/%m')\n",
    "plt.plot(vendas_diarias['DATA'], vendas_diarias['VALOR_TOTAL'])\n",
    "vendas_diarias = vendas_diarias.sort_values(by=['VALOR_TOTAL'], ascending=False)\n",
    "vendas_diarias[['DATA', 'VALOR_TOTAL']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com as observações feitas acima, conseguimos tirar de cara algumas conclusões:\n",
    "\n",
    "O mês (de acordo com os dados fornecidos) com maior número de vendas e valor arrecadado é Julho. O mês de Setembro tem um valor de apenas 140 reais arrecadados, mas isso se deve ao fato de estarmos considerando apenas o primeiro dia de Setembro.\n",
    "\n",
    "O produto mais vendido é o item D, com uma diferença considerável para os outros produtos, sendo que a média de quantidade vendida dos outros produtos é 213, com um desvio padrão muito pequeno, enquanto o produto D teve 249 unidades vendidas!\n",
    "\n",
    "Por fim, na análise do gráfico de vendas diárias, percebemos que o faturamento da rede depende fortemente de picos, sendo que existem dias que não existe nenhum pedido! Após uma análise mais aprofundada, percebi que os dias com maior faturamento são sempre no período de SEXTA-FEIRA até DOMINGO.\n",
    "Colocando os 10 dias com maior número de vendas em ordem decrescente, percebemos que TODOS os 10 pertencem a este período de dias da semana!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que temos nossas observações concluidas, irei implementar um modelo preditivo para ajudar a calcular a demanda do negócio.\n",
    "Devido a grande maioria das colunas não servirem para features (por não terem relação direta com a quantidade ou por ainda não serem preenchidas), usarei uma regressão linear, que utilizará as datas cadastradas para previsão das datas futuras. Vale ressaltar que o dataset fornecido é relativamente pequeno, então a precisão do modelo pode ser aumentada junto a implementação de mais dados. Dias já cadastrados também terão maior precisão do que dias não registrados no banco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrupando datas e quantidades\n",
    "diario_data = df.groupby('DATA').agg({'QUANTIDADE': 'sum'}).reset_index()\n",
    "\n",
    "# Criar variáveis de features (Ano, Mês e Dia)\n",
    "diario_data['Ano'] = diario_data['DATA'].dt.year\n",
    "diario_data['Mes'] = diario_data['DATA'].dt.month\n",
    "diario_data['Dia_do_Ano'] = diario_data['DATA'].dt.dayofyear\n",
    "\n",
    "# Dividir em conjunto de treinamento e teste\n",
    "X = diario_data[['Ano', 'Mes', 'Dia_do_Ano']]\n",
    "y = diario_data['QUANTIDADE']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Treinar o modelo de regressão linear\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Imprimir os coeficientes\n",
    "print(\"Coeficientes: \", model.coef_)\n",
    "print(\"Erro Médio Quadratico: \", metrics.mean_squared_error(y_test, y_pred))\n",
    "print(\"Erro Médio Absoluto: \", metrics.mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aqui simulei como valor de entrada um dia que já havia sido cadastrado no banco, no qual a quantia consumida foi de 10 unidades\n",
    "#O resultado da previsão foi de 12 unidades\n",
    "novo_dado = pd.DataFrame({\n",
    "    'Ano': [2021],\n",
    "    'Mes': [6],\n",
    "    'Dia_do_Ano': [155]\n",
    "})\n",
    "\n",
    "previsao = model.predict(novo_dado)\n",
    "print(\"Previsão para o dado específico: \", previsao[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aqui exibo um gráfico dos dados de testes e os dados gerados pelas predições\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_test['Dia_do_Ano'], y_test, color='green', label='Dados de Teste')\n",
    "plt.scatter(X_test['Dia_do_Ano'], y_pred, color='red', label='Previsões')\n",
    "plt.xlabel('Dia do Ano')\n",
    "plt.ylabel('Quantidade')\n",
    "plt.title('Previsões vs Dados Reais - Demanda Diária')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Avaliação do modelo e Recomendações*\n",
    "\n",
    "Após todo tratamento dos dados, análise exploratória, análise descritiva, treinamento dos dados e avaliação dos mesmos, tiramos algumas conclusões e insights para recomendar para a Mr.Health.\n",
    "\n",
    "1. Os dados são passíveis de tratamento, porém, uma mudança na forma da captação para melhor cuidado e organização são sugestões;\n",
    "\n",
    "2. A quantidade de dados é considerada pequena para um modelo de predição. É valido informar ao cliente leigo na área que quanto maior a quantidade de dados captados, maior a precisão do modelo (Predição mais próxima do número real de demanda);\n",
    "\n",
    "3. O item D é o produto mais vendido, com boa margem para os outros, então um investimento no marketing deste produto pode alavancar as vendas totais;\n",
    "\n",
    "4. Dos poucos meses registrados, o mês de Julho foi o com mais vendas, então uma preparação para promoções ou coisas do tipo, são válidas para este mês;\n",
    "\n",
    "5. Com a análise de vendas diárias, percebemos que a avassaladora maioria dos pedidos são feitos no fim de semana (SEX-SAB-DOM), e pelo gráfico identificamos que a loja depende muito destes picos, então atitudes para garantia de estoque nos finais de semana são consideráveis, além também da empresa considerar o por que de não gerar tantas vendas durante a semana e, tomar medidas cabíveis e possíveis.\n",
    "\n",
    "6. O estoque necessário para a semana não é tão alto, mas para os finais de semana sim, então dependendo da frequência do fornecimento de estoque, pode ser necessário cargas maiores pensando no futuro próximo (Ex: Caso o fornecimento seja feito semanalmente, escolher um dia como quinta ou sexta feira para não correr riscos de faltar no pico e, caso necessário durante a semana, pequenas quantidades de suprimentos podem ser adquiridas a parte)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
